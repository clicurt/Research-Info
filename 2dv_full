#include <opencv2/dnn.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/highgui.hpp>

#include <iostream>
#include <chrono>
#include <random>
#include <set>
#include <cmath>
#include <fstream>
// #include <algorithm>

cv::Mat g_test_output_frame;
using namespace std;
struct KeyPoint
{
	KeyPoint(cv::Point point, float score)
	{
		this->id = -1;
		this->point = point;
		this->score = score;
	}

	int id;
	cv::Point point;
	float score;
};
//Reload << output keypoint
// std::ostream &operator<<(std::ostream &os, const KeyPoint &kp)
// {
// 	os << "Id:" << kp.id << ", Point:" << kp.point << ", Prob:" << kp.score << std::endl;
// 	return os;
// }

////////////////////////////////
struct ValidPair
{
	ValidPair(int aId, int bId, float score)
	{
		this->aId = aId;
		this->bId = bId;
		this->score = score;
	}

	int aId;
	int bId;
	float score;
};

//Overload << output pair
// std::ostream &operator<<(std::ostream &os, const ValidPair &vp)
// {
// 	os << "A:" << vp.aId << ", B:" << vp.bId << ", score:" << vp.score << std::endl;
// 	return os;
// }

////////////////////////////////
//Overload << output vector
// template <class T>
// std::ostream &operator<<(std::ostream &os, const std::vector<T> &v)
// {
// 	os << "[";
// 	bool first = true;
// 	for (typename std::vector<T>::const_iterator ii = v.begin(); ii != v.end(); ++ii, first = false)
// 	{
// 		if (!first)
// 			os << ",";
// 		os << " " << *ii;
// 	}
// 	os << "]"; //<<std::endl;;
// 	return os;
// }
//Overload << output set
// template <class T>
// std::ostream &operator<<(std::ostream &os, const std::set<T> &v)
// {
// 	os << "[";
// 	bool first = true;
// 	for (typename std::set<T>::const_iterator ii = v.begin(); ii != v.end(); ++ii, first = false)
// 	{
// 		if (!first)
// 			os << ",";
// 		os << " " << *ii;
// 	}
// 	os << "]";
// 	return os;
// }

////////////////////////////////
//COCO model
const int kPoints = 18;
//Name each key point, a total of 18, excluding the background
//Nose-0, neck-1, right shoulder-2, right elbow-3, right wrist-4, left shoulder-5, left elbow-6, left wrist-7, right hip-8, right knee-9,
//Right ankle-10, left hip-11, left knee-12, left ankle-13, right eye-14, left eye-15, ear-16, left ear-17
const std::string keypointsMapping[] = {
	"Nose", "Neck",
	"R-Sho", "R-Elb", "R-Wr",
	"L-Sho", "L-Elb", "L-Wr",
	"R-Hip", "R-Knee", "R-Ank",
	"L-Hip", "L-Knee", "L-Ank",
	"R-Eye", "L-Eye", "R-Ear", "L-Ear"};
//posePairs look at the next structure, the output index of posePairs, for example, 1,2 corresponds to 31,32; 1,5 corresponds to 39,40
//A total of 19 pairs
const std::vector<std::pair<int, int>> mapIdx = {
	{31, 32}, {39, 40}, {33, 34}, {35, 36}, {41, 42}, {43, 44}, {19, 20}, {21, 22}, {23, 24}, {25, 26}, 
	{27, 28}, {29, 30}, {47, 48}, {49, 50}, {53, 54}, {51, 52}, {55, 56}, {37, 38}, {45, 46}};

//0 is connected to 1, 14, 15 respectively
//Nose is connected to Neck, Right Eye and Left Eye respectively
//A total of 19 pairs
const std::vector<std::pair<int, int>> posePairs = {
	{1, 2}, {1, 5}, {2, 3}, {3, 4}, {5, 6}, {6, 7}, {1, 8}, {8, 9}, {9, 10}, {1, 11}, 
	{11, 12}, {12, 13}, {1, 0}, {0, 14}, {14, 16}, {0, 15}, {15, 17}, {2, 17}, {5, 16}};


// void output_draw_contours(cv::OutputArrayOfArrays &in)
// {
// 	cv::drawContours(g_test_output_frame, in, -1, cv::Scalar::all(255));
// 	cv::imshow("Contours", g_test_output_frame);
// }

//Use NMS (Non Maximum Suppression) for Confidence Map to detect key points.
//probMap  smoothProbMap maskedProbMap
//probMap->smoothProbMap->maskedProbMap

//findContours function
//    contour
// beautiful ['kɑːntʊr]
// English ['kɒntʊə]
// n. Contour line / weekly line / circuit / summary
// v. To fit a certain contour / follow the contour of the terrain / draw the contour / draw the contour

//void cv::findContours(
// cv::InputOutputArray image, // input 8-bit single-channel "binary" image
// cv::OutputArrayOfArrays contours, // vector of vectors containing points
// cv::OutputArray hierarchy, // (optional) topology information
// int mode, // contour retrieval mode
// int method, // approximate method
// cv::Point offset = cv::Point() // (optional) the offset of all points
//);

//The findContours below is currently used
//void cv::findContours(
// cv::InputOutputArray image, // input 8-bit single-channel "binary" image
// cv::OutputArrayOfArrays contours, // a vector of vectors containing points is equivalent to std::vector<std::vector<cv::Point>>
// int mode, // contour retrieval mode
// int method, // approximate method
// cv::Point offset = cv::Point() // (optional) the offset of all points
//);

//The contour retrieval mode currently used is cv::RETR_TREE
//cv::RETR_EXTERNAL: means that only the outermost contour is extracted;
//cv::RETR_LIST: means to extract all contours and put them in the list;
//cv::RETR_CCOMP: Means to extract all contours and organize them into a two-layer structure, where the top contour is the outer contour, and the second contour is the "hole" contour;
//cv::RETR_TREE: Indicates that all contours are extracted and organized into a complete hierarchical structure of contour nesting.
//---------------------------------------------------------------------------------------------
//void GaussianBlur(InputArray src, OutputArray dst, Size ksize, double sigmaX, double sigmaY=0, int borderType=BORDER_DEFAULT ) ;
//Function: Use dst to output the input image src after Gaussian filtering.
//Parameters: src and dst are of course the input image and output image respectively. Ksize is the size of the Gaussian filter template, sigmaX and sigmaY are the filter coefficients of the Gaussian filter in the horizontal and vertical directions, respectively. borderType is the edge extension point interpolation type.

void getKeyPoints(cv::Mat &probMap, double threshold, std::vector<KeyPoint> &keyPoints)
{
	//For each key point, we apply a threshold to the confidence map (in this example, 0.1)
	cv::Mat smoothProbMap;
	cv::GaussianBlur(probMap, smoothProbMap, cv::Size(3, 3), 0, 0);

	cv::Mat maskedProbMap;
	//Remove the noise https://docs.opencv.org/4.2.0/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57
	cv::threshold(smoothProbMap, maskedProbMap, threshold, 255, cv::THRESH_BINARY);

	maskedProbMap.convertTo(maskedProbMap, CV_8U, 1);

	//-Display 3 different types of mat
	// cv::imshow("probMap", probMap);
	// cv::imshow("smoothProbMap", smoothProbMap);
	// cv::imshow("maskedProbMap", maskedProbMap);

	//Keypoint region keypoint region
	//Find the contours of all areas corresponding to the key points (contour)
	std::vector<std::vector<cv::Point>> contours;
	cv::findContours(maskedProbMap, contours, cv::RETR_TREE, cv::CHAIN_APPROX_SIMPLE);
	// std::cout << contours;
	// output_draw_contours(contours);
	//For each key point contour area, find the maximum value.
	for (size_t i = 0; i < contours.size(); ++i)
	{
		cv::Mat blobMask = cv::Mat::zeros(smoothProbMap.rows, smoothProbMap.cols, smoothProbMap.type());

		//Fill the convex polygon, only need to provide the vertices of the convex polygon
		cv::fillConvexPoly(blobMask, contours[i], cv::Scalar(1));

		double maxVal;
		cv::Point maxLoc;
		//Extract the local maximum value of the key point area, similar to the previous target detection
		// MatExpr cv::Mat::mul 	( 	InputArray  	m,double  	scale = 1) 		const

		//        Performs an element-wise multiplication or division of the two matrices.
		//        The method returns a temporary object encoding per-element array multiplication, with optional scale.
		//                Note that this is not a matrix multiplication that corresponds to a simpler "\*" operator.
		//https://docs.opencv.org/4.2.0/d3/d63/classcv_1_1Mat.html#a385c09827713dc3e6d713bfad8460706
		// Perform element-wise multiplication or division of two matrices.

		// This method returns a temporary object encoding the multiplication of each element of the array, with an optional number of decimal places. Please note that this is not a matrix multiplication corresponding to the simpler "\*" operator.
		cv::minMaxLoc(smoothProbMap.mul(blobMask), 0, &maxVal, 0, &maxLoc);

		//We store coordinates (x, y), confidence score for each key point
		//maxLoc is the coordinate
		keyPoints.push_back(KeyPoint(maxLoc, probMap.at<float>(maxLoc.y, maxLoc.x)));
	}
}

void populateColorPalette(std::vector<cv::Scalar> &colors, int nColors)
{
	std::random_device rd;
	std::mt19937 gen(rd());
	std::uniform_int_distribution<> dis1(64, 200);
	std::uniform_int_distribution<> dis2(100, 255);
	std::uniform_int_distribution<> dis3(100, 255);

	for (int i = 0; i < nColors; ++i)
	{
		colors.push_back(cv::Scalar(dis1(gen), dis2(gen), dis3(gen)));
	}
}

void splitNetOutputBlobToParts(cv::Mat &netOutputBlob, const cv::Size &targetSize, std::vector<cv::Mat> &netOutputParts)
{
	//size refers to the size of each dimension in the multi-dimensional matrix, nParts is 57
	int nParts = netOutputBlob.size[1];

	int h = netOutputBlob.size[2];
	int w = netOutputBlob.size[3];

	for (int i = 0; i < nParts; ++i)
	{
		cv::Mat part(h, w, CV_32F, netOutputBlob.ptr(0, i));

		cv::Mat resizedPart;

		//Restore the image size of the output result to its original size
		cv::resize(part, resizedPart, targetSize);

		netOutputParts.push_back(resizedPart);
	}
}
//Sampling between points a and b, connect a line segment between a and b, and take numPoints points uniformly on the line
void populateInterpPoints(const cv::Point &a, const cv::Point &b, int numPoints, std::vector<cv::Point> &interpCoords)
{
	float xStep = ((float)(b.x - a.x)) / (float)(numPoints - 1);
	float yStep = ((float)(b.y - a.y)) / (float)(numPoints - 1);

	interpCoords.push_back(a);

	for (int i = 1; i < numPoints - 1; ++i)
	{
		interpCoords.push_back(cv::Point(a.x + xStep * i, a.y + yStep * i));
	}

	interpCoords.push_back(b);
}

//Different key points are connected to form a pair, to obtain a valid pair
void getValidPairs(const std::vector<cv::Mat> &netOutputParts,
				   const std::vector<std::vector<KeyPoint>> &detectedKeypoints,
				   std::vector<std::vector<ValidPair>> &validPairs,
				   std::set<int> &invalidPairs)
{

	int nInterpSamples = 10; //Number of samples
	float pafScoreTh = 0.1;
	float confTh = 0.7;
	//mapIdx size 19, 4 layer loop can reduce the number of calculations
	//mapIdx and posePairs are one-to-one correspondence
	for (size_t k = 0; k < mapIdx.size(); ++k)
	{

		//A->B constitute a limb
		//Part Affinity Fields
		//Retrieve from netOutputParts according to the key-value pair of mapIdx, the value retrieved by key is counted as PAF_A, and the value retrieved by value is counted as a PAF_B
		//Here first refers to the key, second refers to the value
		cv::Mat pafA = netOutputParts[mapIdx[k].first];
		cv::Mat pafB = netOutputParts[mapIdx[k].second];

		//Find the keypoints for the first and second limb
		//Find the key point positions of the first limb and the second limb
		//According to the key-value pairs of posePairs from the detectedKeypoints, the value taken by key is counted as CAND_A, and the value taken by value is counted as CAND_B
		//CAND_A and CAND_B are connected to be candidate limb
		const std::vector<KeyPoint> &candA = detectedKeypoints[posePairs[k].first];
		const std::vector<KeyPoint> &candB = detectedKeypoints[posePairs[k].second];

		//candA and candB are equal or not because of the detection results
		int nA = candA.size();
		int nB = candB.size();

		/*
          # If keypoints for the joint-pair is detected
          # check every joint in candA with every joint in candB
          # Calculate the distance vector between the two joints
          # Find the PAF values at a set of interpolated points between the joints
          # Use the above formula to compute a score to mark the connection valid
         */
		/*
 If the key point position of the joint-pair is detected, then,
 Check each joint in candA and candB.
 Calculate the distance vector between two joints.
 Calculate the PAF value of the set of interpolation points between two joints.
 Use the formula in the paper to calculate the score value and judge the validity of the connection.

 */

		if (nA != 0 && nB != 0)
		{
			std::vector<ValidPair> localValidPairs;

			for (int i = 0; i < nA; ++i)
			{
				int maxJ = -1;
				float maxScore = -1;
				bool found = false;

				for (int j = 0; j < nB; ++j)
				{
					std::pair<float, float> distance(candB[j].point.x - candA[i].point.x, candB[j].point.y - candA[i].point.y);

					float norm = std::sqrt(distance.first * distance.first + distance.second * distance.second);

					if (!norm)
					{
						continue;
					}

					distance.first /= norm;
					distance.second /= norm;

					//Find p(u)
					std::vector<cv::Point> interpCoords; //Sampling between points A and B, connect a line segment between A and B, and take nInterpSamples=10 points uniformly on the line
					populateInterpPoints(candA[i].point, candB[j].point, nInterpSamples, interpCoords);
					//Find L(p(u))　　pafA, pafB stores the value output by the model
					std::vector<std::pair<float, float>> pafInterp;
					for (size_t l = 0; l < interpCoords.size(); ++l)
					{
						pafInterp.push_back(
							std::pair<float, float>(
								pafA.at<float>(interpCoords[l].y, interpCoords[l].x),
								pafB.at<float>(interpCoords[l].y, interpCoords[l].x)));
					}
					//Calculate the dot product to get the similarity
					std::vector<float> pafScores;
					float sumOfPafScores = 0;
					int numOverTh = 0;
					for (size_t l = 0; l < pafInterp.size(); ++l)
					{
						float score = pafInterp[l].first * distance.first + pafInterp[l].second * distance.second;
						sumOfPafScores += score;
						if (score > pafScoreTh)
						{
							++numOverTh;
						}

						pafScores.push_back(score);
					}
					//Calculate the average of similarity
					float avgPafScore = sumOfPafScores / ((float)pafInterp.size());

					//Choose the largest
					if (((float)numOverTh) / ((float)nInterpSamples) > confTh)
					{
						if (avgPafScore > maxScore)
						{
							maxJ = j;
							maxScore = avgPafScore;
							found = true;
						}
					}

				} /* j */

				if (found)
				{
					localValidPairs.push_back(ValidPair(candA[i].id, candB[maxJ].id, maxScore));
				}

			} /* i */

			validPairs.push_back(localValidPairs);
		}
		else
		{
			invalidPairs.insert(k);
			validPairs.push_back(std::vector<ValidPair>());
		}
	} /* k */
}

//Get a collection of key points belonging to everyone
//First connect the key points two by two to form a pair, and then the pair of key points form the posture of the human body
void getPersonwiseKeypoints(const std::vector<std::vector<ValidPair>> &validPairs,
							const std::set<int> &invalidPairs,
							std::vector<std::vector<int>> &personwiseKeypoints)
{
	for (size_t k = 0; k < mapIdx.size(); ++k)
	{
		if (invalidPairs.find(k) != invalidPairs.end())
		{
			continue;
		}

		const std::vector<ValidPair> &localValidPairs(validPairs[k]);

		int indexA(posePairs[k].first);
		int indexB(posePairs[k].second);

		for (size_t i = 0; i < localValidPairs.size(); ++i)
		{
			bool found = false;
			int personIdx = -1;

			for (size_t j = 0; !found && j < personwiseKeypoints.size(); ++j)
			{
				if (indexA < static_cast<int>(personwiseKeypoints[j].size()) &&
					personwiseKeypoints[j][indexA] == localValidPairs[i].aId)
				{
					personIdx = j;
					found = true;
				}
			} /* j */

			if (found)
			{
				personwiseKeypoints[personIdx].at(indexB) = localValidPairs[i].bId;
			}
			else if (k < 17)
			{
				std::vector<int> lpkp(std::vector<int>(18, -1));

				lpkp.at(indexA) = localValidPairs[i].aId;
				lpkp.at(indexB) = localValidPairs[i].bId;

				personwiseKeypoints.push_back(lpkp);
			}

		} /* i */
	}	  /* k */
}


struct TrackerResult {
    string limb[18];
    string limb1;
    string limb2;
    string limb3;
    string limb4;
    string limb5;
    string limb6;
    string limb7;
    string limb8;
    string limb9;
    string limb10;
    string limb11;
    string limb12;
    string limb13;
    string limb14;
    string limb15;
    string limb16;
    string limb17;
    string limb18;
	string nvFeatureCoor;
	string nvFeature;
	int left;
	int right;
	int top;
	int bottom;
	vector<uchar> imageBinary;
};

void send_data(std::ostream& o, const std::vector<uchar>& v)
{
    o.write(reinterpret_cast<const char*>(v.data()), v.size());
}

template <typename ContainerType>
bool fully_populated(const ContainerType& container)
{
    for (auto& contained : container)
        if (contained.empty()) return false;

    return true;
}

int main(int argc, char **argv)
{
	std::string inputFile = "/home/ub/Pictures/a3.jpeg";
	// std::string inputFile = "/home/ub/Pictures/tester.jpg";

	if (argc > 1)
	{
		inputFile = std::string(argv[1]);
	}

	cv::Mat input = cv::imread(inputFile, cv::IMREAD_COLOR);
	//-----------------------------------------

	std::chrono::time_point<std::chrono::system_clock> startTP = std::chrono::system_clock::now();
	//Load model
	cv::dnn::Net inputNet = cv::dnn::readNetFromCaffe("/home/ub/project/openpose/openpose-Multi-Person/pose/coco/pose_deploy_linevec.prototxt","/home/ub/project/openpose/openpose-Multi-Person/pose/coco/pose_iter_440000.caffemodel");

	//The input height is fixed at 368, and the input width is calculated according to the aspect ratio.

	cv::Mat inputBlob = cv::dnn::blobFromImage(input, 1.0 / 255.0, cv::Size((int)((368 * input.cols) / input.rows), 368), cv::Scalar(0, 0, 0), false, false);

	inputNet.setInput(inputBlob);

	cv::Mat netOutputBlob = inputNet.forward();

	//netOutputBlob is a 4-dimensional matrix:
	// The first dimension is ignored
	// The second dimension For the COCO model, it consists of 57 parts, size[1]
	// 18 key points confidence map (confidence Map) + 1 background + 19*2 Part Affinity Map.
	//    18+1+38=57
	// The third dimension is the height of the output image. row size[2]
	// The fourth dimension is the width of the output image. col size[3]

	std::vector<cv::Mat> netOutputParts; //One dimension, size is 57

	//The parameter is the size of the original picture, not the size after resize, 57 parts should be separated
	splitNetOutputBlobToParts(netOutputBlob, cv::Size(input.cols, input.rows), netOutputParts);

	std::chrono::time_point<std::chrono::system_clock> finishTP = std::chrono::system_clock::now();

	// std::cout << "Time Taken in forward pass = " << std::chrono::duration_cast<std::chrono::milliseconds>(finishTP - startTP).count() << " ms" << std::endl;

	int keyPointId = 0;
	//If you design the output of the interface, you can design the following data structure 1 (the interface should output part and pair)
	//detectedKeypoints, keyPointsList store the same content, one is stored in two dimensions, the other is stored in one dimension
	std::vector<std::vector<KeyPoint>> detectedKeypoints; //Two-dimensional, all key points of everyone are stored
	std::vector<KeyPoint> keyPointsList;				  //One-dimensional, in order to draw a line between two key points, it is easy to take out the keypoint, so another keyPointsList is defined
	                               				  //One-dimensional, in order to draw a line between two key points, it is easy to take out the keypoint, so another keyPointsList is defined
	                				  //One-dimensional, in order to draw a line between two key points, it is easy to take out the keypoint, so another keyPointsList is defined

	g_test_output_frame = input.clone();
	for (int i = 0; i < kPoints; ++i)
	{
		std::vector<KeyPoint> keyPoints;
		// 0.1 is the threshold
		//-----------------------
		// cv::Mat output_part = netOutputParts[i].clone();//Used to show the analysis code of each part
		//        cv::imshow("netOutputParts", output_part);
		//        cv::waitKey(0);
		//------------------------------------------
		getKeyPoints(netOutputParts[i], 0.1, keyPoints);

		//std::cout << "Keypoints - " << keypointsMapping[i] << " : " << keyPoints << std::endl;
		//Take the output of the left ear as an example
		// When there is only one person
		//Keypoints - L-Ear : [ Id:0, Point:[281, 89], Prob:0.784812]

		// When there are multiple people
		//        Keypoints - L-Ear :
		//        [ Id:88, Point:[335, 175], Prob:0.62902
		//        , Id:89, Point:[189, 175], Prob:0.590987
		//        , Id:90, Point:[260, 175], Prob:0.714218
		//        , Id:91, Point:[76, 173], Prob:0.573334
		//        , Id:92, Point:[125, 167], Prob:0.353028
		//        , Id:93, Point:[455, 159], Prob:0.258485
		//        ]

		// This will output 18 key points in turn

		for (size_t i = 0; i < keyPoints.size(); ++i, ++keyPointId)
		{
			keyPoints[i].id = keyPointId;
		}

		// if(keyPoints.at(i).point.x != 0 && keyPoints.at(i).point.y != 0) {
		// 	for (size_t ix = 0; ix < 3; ix++) {
		// 		eachPersonStr += to_string(keyPoints.at(ix).point.x) + "\n";
		// 	}
		// } else {
		// 	eachPersonStr += "0,0,0.0000\n";
		// 	// eachPerson.push_back("0,0,0.0000");
		// }
		
		
		// std::cout << "Keypoints - " << keypointsMapping[i] << " : " << keyPoints << std::endl;

		//id is like this, starting from 0 and accumulating backwards in turn. Assuming that there are 6 people in total, 3 noses are detected, namely 0,1,2, then the id of the neck starts from 3.
		//Instead of starting from 6, there is no need to reserve positions for the noses of all 6 people.
		detectedKeypoints.push_back(keyPoints);
		keyPointsList.insert(keyPointsList.end(), keyPoints.begin(), keyPoints.end());
	}
	// for (auto keyp : eachPerson)
	// {
	// 	cout << "eachPerson : " << keyp << endl;
	// }
	

	//Fill the palette
	std::vector<cv::Scalar> colors;
	populateColorPalette(colors, kPoints);

	cv::Mat outputFrame = input.clone();

	//Draw all the key points and keypoints on the picture,
	for (int i = 0; i < kPoints; ++i)
	{
		for (size_t j = 0; j < detectedKeypoints[i].size(); ++j)
		{
			cv::circle(outputFrame, detectedKeypoints[i][j].point, 5, colors[i], -1, cv::LINE_AA);
		}
	}
	// Only draw the keypoint at this time, the pair has not been calculated

	std::vector<std::vector<ValidPair>> validPairs;
	std::set<int> invalidPairs;
	getValidPairs(netOutputParts, detectedKeypoints, validPairs, invalidPairs);
	std::cout << "size of validPairs: "<<validPairs.size() << endl;
	std::cout << "size of invalidPairs: "<<invalidPairs.size() << endl;
	

	//One point has xy; two points can be connected to form a pair.
	//Nose 1 is connected to Neck 2 and LAnkle 5 respectively {1,2}, {1,5}
	//Here can only be connected in a certain direction, for example, nose is connected to neck, not the opposite direction of neck is connected to nose
	std::vector<std::vector<int>> personwiseKeypoints; //Two-dimensional

	//All pairs are assigned to different people
	getPersonwiseKeypoints(validPairs, invalidPairs, personwiseKeypoints);
	std::cout << "netOutputParts: "<<netOutputParts.size() << endl;
	std::cout << "detectedKeypoints: "<<detectedKeypoints.size() << endl;
	std::cout << "getPersonwiseKeypoints of validPairs: "<<validPairs.size() << endl;
	std::cout << "getPersonwiseKeypoints of invalidPairs: "<<invalidPairs.size() << endl;

	//If you design the output of the interface, you can design the following data structure 2
	//Assuming it is a person, all 18 key points are not occluded and all detected personwiseKeypoints The result is (here is the id of the key point)
	//[ [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]]

	//Assuming two people, the following -1 means that the key point is not detected or the key point is not connected to other key points
	//One line represents the id of a person’s key point, which can be connected to other key points
	//    [ [ 0, 2, 4, -1, -1, 8, -1, -1, -1, -1, -1, -1, -1, -1, 10, -1, 12, -1],
	//    [ 1, 3, 5, -1, -1, 9, -1, -1, -1, -1, -1, -1, -1, -1, -1, 11, -1, 13]]

	//A little more people can see clearly, the result of personwiseKeypoints
	//    [
	//    [ -1, 3, 9, 17, 20, 26, 31, 36, 41, 48, 54, 59, 66, 73, -1, -1, -1, -1],
	//    [ -1, 4, 11, 16, 22, 27, 33, 38, 43, 50, 56, 61, 68, 74, -1, -1, -1, -1],
	//    [ -1, 5, 10, 15, 21, 28, 32, 37, 42, 49, 55, 62, 67, 72, -1, -1, -1, -1],
	//    [ 1, 6, 13, 19, 25, -1, -1, -1, 45, 51, 58, 63, 69, 76, 78, 80, -1, 91],
	//    [ 2, 7, 12, 17, -1, 29, 34, 39, 44, 47, 53, 60, 65, 71, 79, 81, 87, 93],
	//    [ -1, 8, 14, 18, 23, 30, 35, 40, 46, 52, 57, 64, 70, 75, -1, -1, -1, -1],
	//    [ 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 77, -1, 86, -1]]

	//The following is to draw a line between every two points, according to the definition of posePairs, to determine which key point can be connected to which key point
	// for (int i = 0; i < kPoints - 1; ++i)
	// {
	// 	for (size_t n = 0; n < personwiseKeypoints.size(); ++n)
	// 	{
	// 		const std::pair<int, int> &posePair = posePairs[i];
	// 		int indexA = personwiseKeypoints[n][posePair.first];
	// 		int indexB = personwiseKeypoints[n][posePair.second];

	// 		//Look at the value of personwiseKeypoints, you know the situation to judge -1
	// 		if (indexA == -1 || indexB == -1)
	// 		{
	// 			continue;
	// 		}

	// 		const KeyPoint &kpA = keyPointsList[indexA];
	// 		const KeyPoint &kpB = keyPointsList[indexB];

	// 		cv::line(outputFrame, kpA.point, kpB.point, colors[i], 3, cv::LINE_AA);
	// 	}
	// }


	vector<string> kpVector;
	// string kpVectorStr;
	int numberOfPersons = personwiseKeypoints.size();
	// if (!numberOfPersons) return false;
	for (int j = 0; j < personwiseKeypoints.size(); j++)
	{
		for (int i = 0; i < detectedKeypoints.size(); i++)
		{
			int point_x, point_y;
			float score;
			// if (!fully_populated(detectedKeypoints)) {
			// 	std::cout << "There is at least one week day with no associated values.\n";
			// 	kpVector.push_back(to_string(0) + ","  + to_string(0) + "," + to_string(0.));
			// 	// break;
				// // break;
			if (detectedKeypoints[i].empty()) {
				std::cout << "There is at least one week day with no associated values.\n";
				kpVector.push_back(to_string(0) + ","  + to_string(0) + "," + to_string(0.));
			} else {
				std::cout << "Fully populated.\n";
				if (detectedKeypoints[i][j].point.x >= 0 && detectedKeypoints[i][j].point.x <= input.cols) {
					// 
					point_x = detectedKeypoints[i][j].point.x;
				} else {
					point_x = 0;
				}
				// if (detectedKeypoints.at(i).at(j).) return;
				if (detectedKeypoints[i][j].point.y >= 0 && detectedKeypoints[i][j].point.y <= input.rows) {
					// 
					point_y = detectedKeypoints[i][j].point.y;
				} else {
					point_y = 0;
				}
				
				if (detectedKeypoints[i][j].score <= 1 && detectedKeypoints[i][j].score > 0 && !std::isnan(score))
					score = detectedKeypoints[i][j].score;
				else
					score = 0;
				kpVector.push_back(to_string(point_x) + ","  + to_string(point_y) + "," + to_string(score));
			}
			// if (std::find(detectedKeypoints[i].begin(), detectedKeypoints[i].end(), detectedKeypoints[i][j].point.x) != detectedKeypoints[i].end()) {
			// 	/* v contains x */
			// 	point_x = detectedKeypoints[i][j].point.x;
			// } else {
			// 	/* v does not contain x */
			// 	point_x = 0;
			// }
			// if (std::find(detectedKeypoints[i].begin(), detectedKeypoints[i].end(), detectedKeypoints[i][j].point.y) != detectedKeypoints[i].end()) {
			// 	/* v contains x */
			// 	point_y = detectedKeypoints[i][j].point.y;
			// } else {
			// 	/* v does not contain x */
			// 	point_y = 0;
			// }
			// if (detectedKeypoints[i].size() <  detectedKeypoints[i + 1].size()) {
			// 	// point_x = 0;
			// 	// point_y = 0;
			// 	kpVector.pop_back();
			// 	// kpVector.push_back(to_string(200) + ","  + to_string(200) + "," + to_string(0.9999));
			// } else if (detectedKeypoints[i].size() > detectedKeypoints[i+1].size()) {
			// 	// point_x = 0;
			// 	// point_y = 0;
			// 	kpVector.push_back(to_string(200) + ","  + to_string(200) + "," + to_string(0.9999));
			// } 
			// else {
			// 	// point_x = detectedKeypoints[i][j].point.x;
			// 	// point_y = detectedKeypoints[i][j].point.y;
			// }
			// cout <<" first :" << detectedKeypoints[j].size()<<", second :" << detectedKeypoints[j+1].size() <<endl;
				
			// if (detectedKeypoints[i][j].point.y < 0 || detectedKeypoints[i][j].point.y < 0) {
			// 	point_x = 0;
			// 	point_y = 0;
			// } else {}
			// 	point_y = detectedKeypoints[i][j].point.y;

			// kpVectorStr += to_string(point_x) + ","  + to_string(point_y) + "," + to_string(detectedKeypoints[i][j].score);
			// kpVector.push_back(to_string(point_x) + ","  + to_string(point_y) + "," + to_string(detectedKeypoints[i][j].score));
			// kpVector.push_back(to_string(200) + ","  + to_string(200) + "," + to_string(0.9999));
			// kpVector.insert(kpVector.end(), 
			// 	to_string(point_x) + ","  + to_string(point_y) + "," + to_string(detectedKeypoints[i][j].score));
		}
	}

	// for (int i = 0; i < kpVector.size(); i++) {
	// 	std::cout << "kpVector : "<<kpVector.at(i) << endl;
	// }
	// for (auto dp : detectedKeypoints){
	// 	cout <<" dec_points :" << dp<<endl;
	// }
	// std::cout << "kpVector size: "<<kpVector.size() << endl;
	// for (auto dp : detectedKeypoints)
	// for (int j = 0; j < personwiseKeypoints.size(); j++) {
	// 	for (int k = 0; k < detectedKeypoints.size(); ++k) {
	// 		// eachPersonStr += to_string(detectedKeypoints.at(j).at(k).point.x) + "\n";
	// 		std::cout << "detectedKeypoints : "<<detectedKeypoints.at(k).at(j).point << endl;
	// 	}

	// }
	

	// int numberOfPersons = detectedKeypoints.at(0).size();
	// int numberOfPersons = personwiseKeypoints.size();
	int size = numberOfPersons;
	// int size = (kpVector.size() - 1) / kPoints + 1;
	std::cout << "size of vector: "<<size << endl;
	std::cout << "size of detectedKeypoints: "<<detectedKeypoints.size() << endl;
	std::cout << "size of personwiseKeypoints: "<<personwiseKeypoints.size() << endl;
	std::cout << "size of personwiseKeypoints: "<<personwiseKeypoints.size() << endl;

	// if (numberOfPersons > 0)
	// {
		vector<string> personsVector[size];

		for (int k = 0; k < size; ++k)
		{
			std::cout << "size of kpVector.size(): "<<kpVector.size() << endl;
			// for (int i = 0; i < kpVector.size(); i++)
			// {
			// get range for next set of n elements
			auto start_itr = std::next(kpVector.cbegin(), k * kPoints);
			auto end_itr = std::next(kpVector.cbegin(), k * kPoints + kPoints);

			// allocate memory for the sub-vector
			personsVector[k].resize(kPoints);

			if (k * kPoints + kPoints > kpVector.size())
			{
				end_itr = kpVector.cend();
				personsVector[k].resize(kpVector.size() - k * kPoints);
			}

			// copy elements from the input range to the sub-vector
			std::copy(start_itr, end_itr, personsVector[k].begin());
			// }
		}
		

		TrackerResult trackerResult;
		vector<TrackerResult> res;

		for (int i = 0; i < numberOfPersons; i++)
		{

			// cout << "numberOfPersons : " << numberOfPersons << endl;
			// const auto lAnkle = poseKeypoints.getSize(2) * (person * poseKeypoints.getSize(1) + 13);
			
			// Common parameters needed
			// const auto numberPeopleDetected = poseKeypoints.getSize(0);
			// const auto numberBodyParts = poseKeypoints.getSize(1);
			// // Easy version
			// const auto x = poseKeypoints[{person, part, 0}];
			// const auto y = poseKeypoints[{person, part, 1}];
			// const auto score = poseKeypoints[{person, part, 2}];
			// // Slightly more efficient version
			// // If you want to access these elements on a huge loop, you can get the index
			// // by your own, but it is usually not faster enough to be worthy
			// const auto baseIndex = poseKeypoints.getSize(2)*(person*numberBodyParts + part);
			// const auto x = poseKeypoints[baseIndex];
			// const auto y = poseKeypoints[baseIndex + 1];
			// const auto score = poseKeypoints[baseIndex + 2];

			// const auto nose = 3 * (2 * 18 + 0);
			// const auto x1 = detectedKeypoints[nose][i];
			// const auto y1 = detectedKeypoints[nose][i];
			// const auto score1 = detectedKeypoints[nose][i];
			// trackerResult.limb1 = std::to_string(x1.point.x) + "," + std::to_string(y1.point.y) + "," + std::to_string(score1.score);

			trackerResult.limb1 = personsVector[i].at(0);
			trackerResult.limb2 = personsVector[i].at(1);
			trackerResult.limb3 = personsVector[i].at(2);
			trackerResult.limb4 = personsVector[i].at(3);
			trackerResult.limb5 = personsVector[i].at(4);
			trackerResult.limb6 = personsVector[i].at(5);
			trackerResult.limb7 = personsVector[i].at(6);
			trackerResult.limb8 = personsVector[i].at(7);
			trackerResult.limb9 = personsVector[i].at(8);
			trackerResult.limb10 = personsVector[i].at(9);
			trackerResult.limb11 = personsVector[i].at(10);
			trackerResult.limb12 = personsVector[i].at(11);
			trackerResult.limb13 = personsVector[i].at(12);
			trackerResult.limb14 = personsVector[i].at(13);
			trackerResult.limb15 = personsVector[i].at(14);
			trackerResult.limb16 = personsVector[i].at(15);
			trackerResult.limb17 = personsVector[i].at(16);
			trackerResult.limb18 = personsVector[i].at(17);

			cout << "==========Person : " << i + 1 << "   ==========" << endl;
			cout << "=================================" << endl;
			cout << "trackerResult.limb1 : " << trackerResult.limb1 << endl;
			cout << "trackerResult.limb2 : " << trackerResult.limb2 << endl;
			cout << "trackerResult.limb3 : " << trackerResult.limb3 << endl;
			cout << "trackerResult.limb4 : " << trackerResult.limb4 << endl;
			cout << "trackerResult.limb5 : " << trackerResult.limb5 << endl;
			cout << "trackerResult.limb6 : " << trackerResult.limb6 << endl;
			cout << "trackerResult.limb7 : " << trackerResult.limb7 << endl;
			cout << "trackerResult.limb8 : " << trackerResult.limb8 << endl;
			cout << "trackerResult.limb9 : " << trackerResult.limb9 << endl;
			cout << "trackerResult.limb10 : " << trackerResult.limb10 << endl;
			cout << "trackerResult.limb11 : " << trackerResult.limb11 << endl;
			cout << "trackerResult.limb12 : " << trackerResult.limb12 << endl;
			cout << "trackerResult.limb13 : " << trackerResult.limb13 << endl;
			cout << "trackerResult.limb14 : " << trackerResult.limb14 << endl;
			cout << "trackerResult.limb15 : " << trackerResult.limb15 << endl;
			cout << "trackerResult.limb16 : " << trackerResult.limb16 << endl;
			cout << "trackerResult.limb17 : " << trackerResult.limb17 << endl;
			cout << "trackerResult.limb18 : " << trackerResult.limb18 << endl;
			trackerResult.top = 0;
			trackerResult.bottom = input.rows;
			trackerResult.left = 0;
			trackerResult.right = input.cols;
			cv::Mat roi(outputFrame, cv::Range(trackerResult.top, trackerResult.bottom), cv::Range(trackerResult.left, trackerResult.right));
			std::vector<uchar> imgbuf(outputFrame.rows * outputFrame.cols);
			// cout << "imbuf b4: " << imgbuf.capacity()<<endl;
			std::vector<int> params = {cv::IMWRITE_JPEG_QUALITY, 95};
			cv::imencode(".bmp", roi, imgbuf);
			// cout << "imbuf: " << imgbuf.capacity()<<endl;

			std::ofstream outfile("/home/ub/Pictures/tests111.bmp", std::ofstream::binary);
			outfile.write(reinterpret_cast<const char *>(imgbuf.data()), imgbuf.size());

			res.emplace_back(trackerResult);
		}
	// }

	cv::imshow("Detected Pose", outputFrame);
	cv::waitKey(0);

	return 0;
}
