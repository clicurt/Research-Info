#include <opencv2/dnn.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/highgui.hpp>

#include <iostream>
#include <chrono>
#include <random>
#include <set>
#include <cmath>
#include <fstream>
// #include <algorithm>

cv::Mat g_test_output_frame;
using namespace std;
struct KeyPoint
{
	KeyPoint(cv::Point point, float score)
	{
		this->id = -1;
		this->point = point;
		this->score = score;
	}

	int id;
	cv::Point point;
	float score;
};
//Reload << output keypoint
// std::ostream &operator<<(std::ostream &os, const KeyPoint &kp)
// {
// 	os << "Id:" << kp.id << ", Point:" << kp.point << ", Prob:" << kp.score << std::endl;
// 	return os;
// }

////////////////////////////////
struct ValidPair
{
	ValidPair(int aId, int bId, float score)
	{
		this->aId = aId;
		this->bId = bId;
		this->score = score;
	}

	int aId;
	int bId;
	float score;
};

//Overload << output pair
// std::ostream &operator<<(std::ostream &os, const ValidPair &vp)
// {
// 	os << "A:" << vp.aId << ", B:" << vp.bId << ", score:" << vp.score << std::endl;
// 	return os;
// }

////////////////////////////////
//Overload << output vector
// template <class T>
// std::ostream &operator<<(std::ostream &os, const std::vector<T> &v)
// {
// 	os << "[";
// 	bool first = true;
// 	for (typename std::vector<T>::const_iterator ii = v.begin(); ii != v.end(); ++ii, first = false)
// 	{
// 		if (!first)
// 			os << ",";
// 		os << " " << *ii;
// 	}
// 	os << "]"; //<<std::endl;;
// 	return os;
// }
//Overload << output set
// template <class T>
// std::ostream &operator<<(std::ostream &os, const std::set<T> &v)
// {
// 	os << "[";
// 	bool first = true;
// 	for (typename std::set<T>::const_iterator ii = v.begin(); ii != v.end(); ++ii, first = false)
// 	{
// 		if (!first)
// 			os << ",";
// 		os << " " << *ii;
// 	}
// 	os << "]";
// 	return os;
// }

////////////////////////////////
//COCO model
const int kPoints = 18;
//Name each key point, a total of 18, excluding the background
//Nose-0, neck-1, right shoulder-2, right elbow-3, right wrist-4, left shoulder-5, left elbow-6, left wrist-7, right hip-8, right knee-9,
//Right ankle-10, left hip-11, left knee-12, left ankle-13, right eye-14, left eye-15, ear-16, left ear-17
const std::string keypointsMapping[] = {
	"Nose", "Neck",
	"R-Sho", "R-Elb", "R-Wr",
	"L-Sho", "L-Elb", "L-Wr",
	"R-Hip", "R-Knee", "R-Ank",
	"L-Hip", "L-Knee", "L-Ank",
	"R-Eye", "L-Eye", "R-Ear", "L-Ear"};
//posePairs look at the next structure, the output index of posePairs, for example, 1,2 corresponds to 31,32; 1,5 corresponds to 39,40
//A total of 19 pairs
const std::vector<std::pair<int, int>> mapIdx = {
	{31, 32}, {39, 40}, {33, 34}, {35, 36}, {41, 42}, {43, 44}, {19, 20}, {21, 22}, {23, 24}, {25, 26}, 
	{27, 28}, {29, 30}, {47, 48}, {49, 50}, {53, 54}, {51, 52}, {55, 56}, {37, 38}, {45, 46}};

//0 is connected to 1, 14, 15 respectively
//Nose is connected to Neck, Right Eye and Left Eye respectively
//A total of 19 pairs
const std::vector<std::pair<int, int>> posePairs = {
	{1, 2}, {1, 5}, {2, 3}, {3, 4}, {5, 6}, {6, 7}, {1, 8}, {8, 9}, {9, 10}, {1, 11}, 
	{11, 12}, {12, 13}, {1, 0}, {0, 14}, {14, 16}, {0, 15}, {15, 17}, {2, 17}, {5, 16}};


// void output_draw_contours(cv::OutputArrayOfArrays &in)
// {
// 	cv::drawContours(g_test_output_frame, in, -1, cv::Scalar::all(255));
// 	cv::imshow("Contours", g_test_output_frame);
// }

//Use NMS (Non Maximum Suppression) for Confidence Map to detect key points.
//probMap  smoothProbMap maskedProbMap
//probMap->smoothProbMap->maskedProbMap

//findContours function
//    contour
// beautiful ['kɑːntʊr]
// English ['kɒntʊə]
// n. Contour line / weekly line / circuit / summary
// v. To fit a certain contour / follow the contour of the terrain / draw the contour / draw the contour

//void cv::findContours(
// cv::InputOutputArray image, // input 8-bit single-channel "binary" image
// cv::OutputArrayOfArrays contours, // vector of vectors containing points
// cv::OutputArray hierarchy, // (optional) topology information
// int mode, // contour retrieval mode
// int method, // approximate method
// cv::Point offset = cv::Point() // (optional) the offset of all points
//);

//The findContours below is currently used
//void cv::findContours(
// cv::InputOutputArray image, // input 8-bit single-channel "binary" image
// cv::OutputArrayOfArrays contours, // a vector of vectors containing points is equivalent to std::vector<std::vector<cv::Point>>
// int mode, // contour retrieval mode
// int method, // approximate method
// cv::Point offset = cv::Point() // (optional) the offset of all points
//);

//The contour retrieval mode currently used is cv::RETR_TREE
//cv::RETR_EXTERNAL: means that only the outermost contour is extracted;
//cv::RETR_LIST: means to extract all contours and put them in the list;
//cv::RETR_CCOMP: Means to extract all contours and organize them into a two-layer structure, where the top contour is the outer contour, and the second contour is the "hole" contour;
//cv::RETR_TREE: Indicates that all contours are extracted and organized into a complete hierarchical structure of contour nesting.
//---------------------------------------------------------------------------------------------
//void GaussianBlur(InputArray src, OutputArray dst, Size ksize, double sigmaX, double sigmaY=0, int borderType=BORDER_DEFAULT ) ;
//Function: Use dst to output the input image src after Gaussian filtering.
//Parameters: src and dst are of course the input image and output image respectively. Ksize is the size of the Gaussian filter template, sigmaX and sigmaY are the filter coefficients of the Gaussian filter in the horizontal and vertical directions, respectively. borderType is the edge extension point interpolation type.

void getKeyPoints(cv::Mat &probMap, double threshold, std::vector<KeyPoint> &keyPoints)
{
	//For each key point, we apply a threshold to the confidence map (in this example, 0.1)
	cv::Mat smoothProbMap;
	cv::GaussianBlur(probMap, smoothProbMap, cv::Size(3, 3), 0, 0);

	cv::Mat maskedProbMap;
	//Remove the noise https://docs.opencv.org/4.2.0/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57
	cv::threshold(smoothProbMap, maskedProbMap, threshold, 255, cv::THRESH_BINARY);

	maskedProbMap.convertTo(maskedProbMap, CV_8U, 1);

	//-Display 3 different types of mat
	// cv::imshow("probMap", probMap);
	// cv::imshow("smoothProbMap", smoothProbMap);
	// cv::imshow("maskedProbMap", maskedProbMap);

	//Keypoint region keypoint region
	//Find the contours of all areas corresponding to the key points (contour)
	std::vector<std::vector<cv::Point>> contours;
	cv::findContours(maskedProbMap, contours, cv::RETR_TREE, cv::CHAIN_APPROX_SIMPLE);
	// std::cout << contours;
	// output_draw_contours(contours);
	//For each key point contour area, find the maximum value.
	for (size_t i = 0; i < contours.size(); ++i)
	{
		cv::Mat blobMask = cv::Mat::zeros(smoothProbMap.rows, smoothProbMap.cols, smoothProbMap.type());

		//Fill the convex polygon, only need to provide the vertices of the convex polygon
		cv::fillConvexPoly(blobMask, contours[i], cv::Scalar(1));

		double maxVal;
		cv::Point maxLoc;
		//Extract the local maximum value of the key point area, similar to the previous target detection
		// MatExpr cv::Mat::mul 	( 	InputArray  	m,double  	scale = 1) 		const

		//        Performs an element-wise multiplication or division of the two matrices.
		//        The method returns a temporary object encoding per-element array multiplication, with optional scale.
		//                Note that this is not a matrix multiplication that corresponds to a simpler "\*" operator.
		//https://docs.opencv.org/4.2.0/d3/d63/classcv_1_1Mat.html#a385c09827713dc3e6d713bfad8460706
		// Perform element-wise multiplication or division of two matrices.

		// This method returns a temporary object encoding the multiplication of each element of the array, with an optional number of decimal places. Please note that this is not a matrix multiplication corresponding to the simpler "\*" operator.
		cv::minMaxLoc(smoothProbMap.mul(blobMask), 0, &maxVal, 0, &maxLoc);

		//We store coordinates (x, y), confidence score for each key point
		//maxLoc is the coordinate
		keyPoints.push_back(KeyPoint(maxLoc, probMap.at<float>(maxLoc.y, maxLoc.x)));
	}
}

void populateColorPalette(std::vector<cv::Scalar> &colors, int nColors)
{
	std::random_device rd;
	std::mt19937 gen(rd());
	std::uniform_int_distribution<> dis1(64, 200);
	std::uniform_int_distribution<> dis2(100, 255);
	std::uniform_int_distribution<> dis3(100, 255);

	for (int i = 0; i < nColors; ++i)
	{
		colors.push_back(cv::Scalar(dis1(gen), dis2(gen), dis3(gen)));
	}
}

void splitNetOutputBlobToParts(cv::Mat &netOutputBlob, const cv::Size &targetSize, std::vector<cv::Mat> &netOutputParts)
{
	//size refers to the size of each dimension in the multi-dimensional matrix, nParts is 57
	int nParts = netOutputBlob.size[1];

	int h = netOutputBlob.size[2];
	int w = netOutputBlob.size[3];

	for (int i = 0; i < nParts; ++i)
	{
		cv::Mat part(h, w, CV_32F, netOutputBlob.ptr(0, i));

		cv::Mat resizedPart;

		//Restore the image size of the output result to its original size
		cv::resize(part, resizedPart, targetSize);

		netOutputParts.push_back(resizedPart);
	}
}
//Sampling between points a and b, connect a line segment between a and b, and take numPoints points uniformly on the line
void populateInterpPoints(const cv::Point &a, const cv::Point &b, int numPoints, std::vector<cv::Point> &interpCoords)
{
	float xStep = ((float)(b.x - a.x)) / (float)(numPoints - 1);
	float yStep = ((float)(b.y - a.y)) / (float)(numPoints - 1);

	interpCoords.push_back(a);

	for (int i = 1; i < numPoints - 1; ++i)
	{
		interpCoords.push_back(cv::Point(a.x + xStep * i, a.y + yStep * i));
	}

	interpCoords.push_back(b);
}

//Different key points are connected to form a pair, to obtain a valid pair
void getValidPairs(const std::vector<cv::Mat> &netOutputParts,
				   const std::vector<std::vector<KeyPoint>> &detectedKeypoints,
				   std::vector<std::vector<ValidPair>> &validPairs,
				   std::set<int> &invalidPairs)
{

	int nInterpSamples = 10; //Number of samples
	float pafScoreTh = 0.1;
	float confTh = 0.7;
	//mapIdx size 19, 4 layer loop can reduce the number of calculations
	//mapIdx and posePairs are one-to-one correspondence
	for (size_t k = 0; k < mapIdx.size(); ++k)
	{

		//A->B constitute a limb
		//Part Affinity Fields
		//Retrieve from netOutputParts according to the key-value pair of mapIdx, the value retrieved by key is counted as PAF_A, and the value retrieved by value is counted as a PAF_B
		//Here first refers to the key, second refers to the value
		cv::Mat pafA = netOutputParts[mapIdx[k].first];
		cv::Mat pafB = netOutputParts[mapIdx[k].second];

		//Find the keypoints for the first and second limb
		//Find the key point positions of the first limb and the second limb
		//According to the key-value pairs of posePairs from the detectedKeypoints, the value taken by key is counted as CAND_A, and the value taken by value is counted as CAND_B
		//CAND_A and CAND_B are connected to be candidate limb
		const std::vector<KeyPoint> &candA = detectedKeypoints[posePairs[k].first];
		const std::vector<KeyPoint> &candB = detectedKeypoints[posePairs[k].second];

		//candA and candB are equal or not because of the detection results
		int nA = candA.size();
		int nB = candB.size();

		/*
          # If keypoints for the joint-pair is detected
          # check every joint in candA with every joint in candB
          # Calculate the distance vector between the two joints
          # Find the PAF values at a set of interpolated points between the joints
          # Use the above formula to compute a score to mark the connection valid
         */
		/*
 If the key point position of the joint-pair is detected, then,
 Check each joint in candA and candB.
 Calculate the distance vector between two joints.
 Calculate the PAF value of the set of interpolation points between two joints.
 Use the formula in the paper to calculate the score value and judge the validity of the connection.

 */

		if (nA != 0 && nB != 0)
		{
			std::vector<ValidPair> localValidPairs;

			for (int i = 0; i < nA; ++i)
			{
				int maxJ = -1;
				float maxScore = -1;
				bool found = false;

				for (int j = 0; j < nB; ++j)
				{
					std::pair<float, float> distance(candB[j].point.x - candA[i].point.x, candB[j].point.y - candA[i].point.y);

					float norm = std::sqrt(distance.first * distance.first + distance.second * distance.second);

					if (!norm)
					{
						continue;
					}

					distance.first /= norm;
					distance.second /= norm;

					//Find p(u)
					std::vector<cv::Point> interpCoords; //Sampling between points A and B, connect a line segment between A and B, and take nInterpSamples=10 points uniformly on the line
					populateInterpPoints(candA[i].point, candB[j].point, nInterpSamples, interpCoords);
					//Find L(p(u))　　pafA, pafB stores the value output by the model
					std::vector<std::pair<float, float>> pafInterp;
					for (size_t l = 0; l < interpCoords.size(); ++l)
					{
						pafInterp.push_back(
							std::pair<float, float>(
								pafA.at<float>(interpCoords[l].y, interpCoords[l].x),
								pafB.at<float>(interpCoords[l].y, interpCoords[l].x)));
					}
					//Calculate the dot product to get the similarity
					std::vector<float> pafScores;
					float sumOfPafScores = 0;
					int numOverTh = 0;
					for (size_t l = 0; l < pafInterp.size(); ++l)
					{
						float score = pafInterp[l].first * distance.first + pafInterp[l].second * distance.second;
						sumOfPafScores += score;
						if (score > pafScoreTh)
						{
							++numOverTh;
						}

						pafScores.push_back(score);
					}
					//Calculate the average of similarity
					float avgPafScore = sumOfPafScores / ((float)pafInterp.size());

					//Choose the largest
					if (((float)numOverTh) / ((float)nInterpSamples) > confTh)
					{
						if (avgPafScore > maxScore)
						{
							maxJ = j;
							maxScore = avgPafScore;
							found = true;
						}
					}

				} /* j */

				if (found)
				{
					localValidPairs.push_back(ValidPair(candA[i].id, candB[maxJ].id, maxScore));
				}

			} /* i */

			validPairs.push_back(localValidPairs);
		}
		else
		{
			invalidPairs.insert(k);
			validPairs.push_back(std::vector<ValidPair>());
		}
	} /* k */
}

//Get a collection of key points belonging to everyone
//First connect the key points two by two to form a pair, and then the pair of key points form the posture of the human body
void getPersonwiseKeypoints(const std::vector<std::vector<ValidPair>> &validPairs,
							const std::set<int> &invalidPairs,
							std::vector<std::vector<int>> &personwiseKeypoints)
{
	for (size_t k = 0; k < mapIdx.size(); ++k)
	{
		if (invalidPairs.find(k) != invalidPairs.end())
		{
			continue;
		}

		const std::vector<ValidPair> &localValidPairs(validPairs[k]);

		int indexA(posePairs[k].first);
		int indexB(posePairs[k].second);

		for (size_t i = 0; i < localValidPairs.size(); ++i)
		{
			bool found = false;
			int personIdx = -1;

			for (size_t j = 0; !found && j < personwiseKeypoints.size(); ++j)
			{
				if (indexA < static_cast<int>(personwiseKeypoints[j].size()) &&
					personwiseKeypoints[j][indexA] == localValidPairs[i].aId)
				{
					personIdx = j;
					found = true;
				}
			} /* j */

			if (found)
			{
				personwiseKeypoints[personIdx].at(indexB) = localValidPairs[i].bId;
			}
			else if (k < 17)
			{
				std::vector<int> lpkp(std::vector<int>(18, -1));

				lpkp.at(indexA) = localValidPairs[i].aId;
				lpkp.at(indexB) = localValidPairs[i].bId;

				personwiseKeypoints.push_back(lpkp);
			}

		} /* i */
	}	  /* k */
}


		}
	// }

	cv::imshow("Detected Pose", outputFrame);
	cv::waitKey(0);

	return 0;
}
